{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers.legacy import RMSprop\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6120d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12500 images of dogs.\n",
      "There are 12500 images of cats.\n"
     ]
    }
   ],
   "source": [
    "# download dataset from https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
    "# downloaded data is in 'tmp/PetImages'\n",
    "\n",
    "\n",
    "source_path = 'tmp/PetImages'\n",
    "\n",
    "source_path_dogs = os.path.join(source_path, 'Dog')\n",
    "source_path_cats = os.path.join(source_path, 'Cat')\n",
    "\n",
    "# Deletes all non-image files (there are two .db files bundled into the dataset)\n",
    "!find tmp/PetImages/ -type f ! -name \"*.jpg\" -exec rm {} +\n",
    "\n",
    "# os.listdir returns a list containing all files under the given path\n",
    "print(f\"There are {len(os.listdir(source_path_dogs))} images of dogs.\")\n",
    "print(f\"There are {len(os.listdir(source_path_cats))} images of cats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9397669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define root directory\n",
    "root_dir = 'tmp/cats-v-dogs'\n",
    "\n",
    "# Empty directory to prevent FileExistsError is the function is run several times\n",
    "if os.path.exists(root_dir):\n",
    "  shutil.rmtree(root_dir)\n",
    "\n",
    "# GRADED FUNCTION: create_train_val_dirs\n",
    "def create_train_val_dirs(root_path):\n",
    "  \"\"\"\n",
    "  Creates directories for the train and test sets\n",
    "  \n",
    "  Args:\n",
    "    root_path (string) - the base directory path to create subdirectories from\n",
    "  \n",
    "  Returns:\n",
    "    None\n",
    "  \"\"\"\n",
    "\n",
    "  train_dir = os.path.join(root_path, 'train')\n",
    "  validation_dir = os.path.join(root_path, 'validation')\n",
    "\n",
    "  train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "  train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "  validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "  validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "  os.makedirs(train_cats_dir)\n",
    "  os.makedirs(train_dogs_dir)\n",
    "  os.makedirs(validation_cats_dir)\n",
    "  os.makedirs(validation_dogs_dir)\n",
    "\n",
    "  \n",
    "try:\n",
    "  create_train_val_dirs(root_path=root_dir)\n",
    "except FileExistsError:\n",
    "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "402827b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/cats-v-dogs/train\n",
      "tmp/cats-v-dogs/validation\n",
      "tmp/cats-v-dogs/train/dogs\n",
      "tmp/cats-v-dogs/train/cats\n",
      "tmp/cats-v-dogs/validation/dogs\n",
      "tmp/cats-v-dogs/validation/cats\n"
     ]
    }
   ],
   "source": [
    "# Testing create_train_val_dirs function\n",
    "\n",
    "for rootdir, dirs, files in os.walk(root_dir):\n",
    "    for subdir in dirs:\n",
    "        print(os.path.join(rootdir, subdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c778ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
    "  \"\"\"\n",
    "  Splits the data into train and test sets\n",
    "  \n",
    "  Args:\n",
    "    SOURCE_DIR (string): directory path containing the images\n",
    "    TRAINING_DIR (string): directory path to be used for training\n",
    "    VALIDATION_DIR (string): directory path to be used for validation\n",
    "    SPLIT_SIZE (float): proportion of the dataset to be used for training\n",
    "    \n",
    "  Returns:\n",
    "    None\n",
    "  \"\"\"\n",
    "  contents = os.listdir(SOURCE_DIR)\n",
    "  random.seed(42)\n",
    "  contents_randomized = random.sample(contents, len(contents))\n",
    "\n",
    "  for i in range(len(contents)):\n",
    "    filename = contents_randomized[i]\n",
    "    file_path = os.path.join(SOURCE_DIR, filename)\n",
    "    if os.path.getsize(file_path):\n",
    "      ratio = i/len(contents_randomized)\n",
    "      if ratio < SPLIT_SIZE:\n",
    "        copyfile(file_path, os.path.join(TRAINING_DIR, filename))\n",
    "      else:\n",
    "        copyfile(file_path, os.path.join(VALIDATION_DIR, filename))\n",
    "    else:\n",
    "      print(f\"{filename} is zero length, so ignoring.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b25974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666.jpg is zero length, so ignoring.\n",
      "11702.jpg is zero length, so ignoring.\n",
      "\n",
      "\n",
      "Original cat's directory has 12500 images\n",
      "Original dog's directory has 12500 images\n",
      "\n",
      "There are 11249 images of cats for training\n",
      "There are 11249 images of dogs for training\n",
      "There are 1250 images of cats for validation\n",
      "There are 1250 images of dogs for validation\n"
     ]
    }
   ],
   "source": [
    "# Test split_data function\n",
    "\n",
    "# Define paths\n",
    "CAT_SOURCE_DIR = \"tmp/PetImages/Cat/\"\n",
    "DOG_SOURCE_DIR = \"tmp/PetImages/Dog/\"\n",
    "\n",
    "TRAINING_DIR = \"tmp/cats-v-dogs/train/\"\n",
    "VALIDATION_DIR = \"tmp/cats-v-dogs/validation/\"\n",
    "\n",
    "TRAINING_CATS_DIR = os.path.join(TRAINING_DIR, \"cats/\")\n",
    "VALIDATION_CATS_DIR = os.path.join(VALIDATION_DIR, \"cats/\")\n",
    "\n",
    "TRAINING_DOGS_DIR = os.path.join(TRAINING_DIR, \"dogs/\")\n",
    "VALIDATION_DOGS_DIR = os.path.join(VALIDATION_DIR, \"dogs/\")\n",
    "\n",
    "# Empty directories in case you run this cell multiple times\n",
    "if len(os.listdir(TRAINING_CATS_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_CATS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TRAINING_DOGS_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_DOGS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(VALIDATION_CATS_DIR)) > 0:\n",
    "  for file in os.scandir(VALIDATION_CATS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(VALIDATION_DOGS_DIR)) > 0:\n",
    "  for file in os.scandir(VALIDATION_DOGS_DIR):\n",
    "    os.remove(file.path)\n",
    "\n",
    "# Define proportion of images used for training\n",
    "split_size = .9\n",
    "\n",
    "# Run the function\n",
    "# NOTE: Messages about zero length images should be printed out\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, VALIDATION_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, VALIDATION_DOGS_DIR, split_size)\n",
    "\n",
    "# Check that the number of images matches the expected output\n",
    "\n",
    "# function should perform copies rather than moving images so original directories should contain unchanged images\n",
    "print(f\"\\n\\nOriginal cat's directory has {len(os.listdir(CAT_SOURCE_DIR))} images\")\n",
    "print(f\"Original dog's directory has {len(os.listdir(DOG_SOURCE_DIR))} images\\n\")\n",
    "\n",
    "# Training and validation splits\n",
    "print(f\"There are {len(os.listdir(TRAINING_CATS_DIR))} images of cats for training\")\n",
    "print(f\"There are {len(os.listdir(TRAINING_DOGS_DIR))} images of dogs for training\")\n",
    "print(f\"There are {len(os.listdir(VALIDATION_CATS_DIR))} images of cats for validation\")\n",
    "print(f\"There are {len(os.listdir(VALIDATION_DOGS_DIR))} images of dogs for validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7ade3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
    "  \"\"\"\n",
    "  Creates the training and validation data generators\n",
    "  \n",
    "  Args:\n",
    "    TRAINING_DIR (string): directory path containing the training images\n",
    "    VALIDATION_DIR (string): directory path containing the testing/validation images\n",
    "    \n",
    "  Returns:\n",
    "    train_generator, validation_generator - tuple containing the generators\n",
    "  \"\"\"\n",
    "\n",
    "  # Instantiate the ImageDataGenerator class \n",
    "  train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
    "                                                      batch_size=20,\n",
    "                                                      class_mode='binary',\n",
    "                                                      target_size=(150, 150))\n",
    "\n",
    "  # Instantiate the ImageDataGenerator class \n",
    "  validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
    "                                                                batch_size=20,\n",
    "                                                                class_mode='binary',\n",
    "                                                                target_size=(150, 150))\n",
    "  return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c38674f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22498 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test generators\n",
    "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f85b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model = tf.keras.models.Sequential([ \n",
    "      tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(512, activation='relu'),\n",
    "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "  ])\n",
    "\n",
    "  \n",
    "  model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['acc']) \n",
    "    \n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b249cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1125/1125 [==============================] - 118s 105ms/step - loss: 0.6027 - acc: 0.6913 - val_loss: 0.5709 - val_acc: 0.7316\n",
      "Epoch 2/15\n",
      "1125/1125 [==============================] - 117s 104ms/step - loss: 0.4600 - acc: 0.7881 - val_loss: 0.4322 - val_acc: 0.8028\n",
      "Epoch 3/15\n",
      "1125/1125 [==============================] - 117s 104ms/step - loss: 0.4005 - acc: 0.8201 - val_loss: 0.5862 - val_acc: 0.7156\n",
      "Epoch 4/15\n",
      "1125/1125 [==============================] - 116s 103ms/step - loss: 0.3574 - acc: 0.8454 - val_loss: 0.4729 - val_acc: 0.8052\n",
      "Epoch 5/15\n",
      "1125/1125 [==============================] - 118s 105ms/step - loss: 0.3295 - acc: 0.8629 - val_loss: 0.4354 - val_acc: 0.8336\n",
      "Epoch 6/15\n",
      "1125/1125 [==============================] - 119s 106ms/step - loss: 0.3074 - acc: 0.8763 - val_loss: 0.5453 - val_acc: 0.8076\n",
      "Epoch 7/15\n",
      "1125/1125 [==============================] - 117s 104ms/step - loss: 0.2952 - acc: 0.8853 - val_loss: 0.4953 - val_acc: 0.8400\n",
      "Epoch 8/15\n",
      "1125/1125 [==============================] - 126s 111ms/step - loss: 0.2864 - acc: 0.8915 - val_loss: 0.4414 - val_acc: 0.8300\n",
      "Epoch 9/15\n",
      "1125/1125 [==============================] - 132s 117ms/step - loss: 0.2748 - acc: 0.8943 - val_loss: 0.4611 - val_acc: 0.8284\n",
      "Epoch 10/15\n",
      "1125/1125 [==============================] - 145s 128ms/step - loss: 0.2744 - acc: 0.8966 - val_loss: 0.6319 - val_acc: 0.8108\n",
      "Epoch 11/15\n",
      "1125/1125 [==============================] - 144s 128ms/step - loss: 0.2660 - acc: 0.9054 - val_loss: 0.5438 - val_acc: 0.7816\n",
      "Epoch 12/15\n",
      "1125/1125 [==============================] - 139s 123ms/step - loss: 0.2669 - acc: 0.9016 - val_loss: 0.5949 - val_acc: 0.8292\n",
      "Epoch 13/15\n",
      "1125/1125 [==============================] - 139s 124ms/step - loss: 0.2770 - acc: 0.9007 - val_loss: 1.0552 - val_acc: 0.7896\n",
      "Epoch 14/15\n",
      "1125/1125 [==============================] - 140s 124ms/step - loss: 0.2811 - acc: 0.8984 - val_loss: 0.6229 - val_acc: 0.8332\n",
      "Epoch 15/15\n",
      "1125/1125 [==============================] - 125s 111ms/step - loss: 0.2795 - acc: 0.8991 - val_loss: 0.6837 - val_acc: 0.8300\n"
     ]
    }
   ],
   "source": [
    "# Get the untrained model\n",
    "model = create_model()\n",
    "\n",
    "# Train the model\n",
    "# Note that this may take some time.\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=15,\n",
    "                    verbose=1,\n",
    "                    validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8bc29854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring non-image file: .DS_Store\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Image: cat-323262_1280.jpg \n",
      " Class: cat (98.2%)\n",
      "Image: bulldog-1224267_1280.jpg \n",
      " Class: dog (54.61%)\n",
      "Image: cat-114782_1280.jpg \n",
      " Class: cat (64.87%)\n",
      "Image: puppy-1903313_640.jpg \n",
      " Class: dog (99.84%)\n",
      "Image: cat-551554_1280.jpg \n",
      " Class: cat (100.0%)\n",
      "Image: puppy-1207816_1280.jpg \n",
      " Class: dog (100.0%)\n",
      "Image: cat-2536662_1280.jpg \n",
      " Class: dog (85.11%)\n",
      "Image: dog-1728494_1280.jpg \n",
      " Class: dog (78.54%)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import numpy as np \n",
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "def test_model(TEST_IMAGES):\n",
    "    allowed_extensions = [\".jpg\", \".jpeg\", \".png\"]\n",
    "\n",
    "    images = os.listdir(TEST_IMAGES)\n",
    "    images_list = []\n",
    "    image_names_list = []\n",
    "\n",
    "    for image in images:\n",
    "        file_extension = os.path.splitext(image)[1]\n",
    "\n",
    "        if file_extension.lower() not in allowed_extensions:\n",
    "            print(f\"Ignoring non-image file: {image}\")\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(TEST_IMAGES, image)\n",
    "        img = load_img(image_path, target_size=(150, 150))\n",
    "        images_list.append(img)\n",
    "        image_names_list.append(image)\n",
    "\n",
    "    images_array = np.zeros((len(images_list), 150, 150, 3))\n",
    "    for i, img in enumerate(images_list):\n",
    "        images_array[i] = img_to_array(img)\n",
    "\n",
    "    images_array /= 255\n",
    "    \n",
    "    classes = model.predict(images_array, batch_size=10)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        if classes[i] > 0.5:\n",
    "            probability = classes[i].item() * 100\n",
    "            results.append(f'dog ({round(probability,2)}%)')\n",
    "        else:\n",
    "            probability = (1 - classes[i].item()) * 100\n",
    "            results.append(f'cat ({round(probability,2)}%)')\n",
    "\n",
    "    return results, image_names_list\n",
    "\n",
    "res,img_list = test_model('tmp/test')\n",
    "\n",
    "for i in range(len(res)):\n",
    "    print(f'Image: {img_list[i]} \\n Class: {res[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e7602cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'images_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(res)\n\u001b[0;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(images_array)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images_array' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f256d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
